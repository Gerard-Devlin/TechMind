[TOC]

---

![Problem-in-training.svg](../assets/images/DL/Problem-in-training.svg)

## 一、常见问题

- *Model Bias*
    - 模型太简单 → 重新设计模型，更有弹性（e.g. 更多feature，deep 
- *Optimization*
    - 梯度下降找到的 $Loss$ 不够低

!!! question
    到底是什么问题？ 

    - 改变模型 → 比如层数增加，loss在training set增加，说明不是overfitting不是弹性不够，而是optimization的问题

- Overfitting
    - 增加训练数据
      - 数据增强（e.g. 图片左右镜像、……
      - 限制模型选择
      - 正则化

!!! tip
    Kaggle 
    
    - Public：公开数据集
      - Private：隐藏数据集，防止为了benchmark而选择出好的模型但其实不行，所以不要用public数据集来调模型
    
    Validation 验证集：使用验证集来**挑**选合适的**模型**

---

## 二、梯度下降问题

梯度下降失败原因（e.g. local minima、saddle point……


??? example "$Hessian$"
      $Hessian$ 矩阵是多元函数的二阶偏导数构成的方阵，在多变量微积分和优化理论中扮演着重要的角色。对于一个具有 $n$ 个变量的函数 $f(x_1, x_2, \ldots, x_n)$，其Hessian矩阵 $H(f)$ 是一个 $n \times n$ 的矩阵，矩阵中的每个元素是函数对一对变量的二阶偏导数。
    
      具体来说，Hessian矩阵 $H(f)$ 的第 $i$ 行第 $j$ 列的元素是函数 $f$ 对变量 $x_i$ 和 $x_j$ 的二阶偏导数，即：
    
      $$
      H(f)_{ij} = \frac{\partial^2 f}{\partial x_i \partial x_j}
      $$
    
      对于一个二元函数 $f(x, y)$，其Hessian矩阵可以表示为：
    
    $$
    H(f) = \begin{bmatrix}
    \frac{\partial^2 f}{\partial x^2} & \frac{\partial^2 f}{\partial x \partial y} \\
    \frac{\partial^2 f}{\partial y \partial x} & \frac{\partial^2 f}{\partial y^2}
    \end{bmatrix}
    $$
    
    
    在临界点处：
    $$
    L(\theta) \approx L(\theta') + \frac{1}{2} (\theta - \theta')^T H (\theta - \theta')
    $$
    
    代入不同的$\theta$ ,
    
    - $v^THv>0\Rightarrow \text{Local minima}$；
    
      - $v^THv<0\Rightarrow \text{Local maxima}$；
    
      - 都有则是 $\text{saddle point}$
    
    性质：
    
    1. **正定性**：如果Hessian矩阵是正定的，该点是局部最小值。
       2. **负定性**：如果Hessian矩阵是负定的，该点是局部最大值。
       3. **不定性**：如果Hessian矩阵是不定的（即有正有负的特征值），那么函数在该点有一个鞍点。

---

## 三、`batch`和`momentum`

### 1、`batch`

`1 epoch` = 把所有 `batch` 运行过一遍 → 每个 `epoch` 后要shuffle

极端：

| Batch Size | 描述                                      | 更新策略                                   |
|-------------------|-------------------------------------------|--------------------------------------------|
| N（全批量）       | 在看到所有20个样本后更新                  | 每个epoch更新一次，**噪声**小             |
| 1                 | 每个样本更新一次，一个epoch更新20次        | 每个样本更新一次，**噪声**大                   |

GPU可以进行**平行运算**，所以`batch size`增加，运行时间不会很明显增加

奇怪：batch size越大，明明噪声小，但是训练结果越差 → optimization fail，可能卡在鞍点

---

### 2、`momentum`

物理世界，球从高处滚下不一定会卡在 $\text{local minima}$ 或者 $\text{saddle point}$，会继续滚动

更新步长，计算方式是上一步的移动量减去当前梯度
$$
\theta_{\text{new}} = \theta - \alpha \left( v + \beta \nabla L(\theta) \right) 
$$
其中：

- $\theta$ 是当前的参数向量。
- $\theta_{\text{new}}$ 是更新后的参数向量。
- $\alpha$ 是学习率。
- $v$ 是动量项，通常是上一步梯度的指数加权平均。
- $\beta$ 是动量系数，控制着动量项的影响程度。
- $\nabla L(\theta)$ 是当前梯度。

---

## 四、自适应学习率

- 有时候 $Loss$ 无法再下降不是因为卡在critical point，而是可能**学习率**选择不合适而导致不能下降，这时候可以通过观察gradient 的norm来判断是由于卡在critical point还是**学习率**选择不合适
    - **学习率**选择过大 → 越过极小值而无法抵达
    - **学习率**选择过小 → 在gradient平缓的地方难以梯度下降

$\text{原始：}\theta_i^{t+1} \leftarrow \theta_i^t - \eta g_i^t$，$g_i^t = \frac{\partial L}{\partial \theta_i} \Big|_{\theta = \theta^t}$

$\text{改进：}\theta_i^{t+1} \leftarrow \theta_i^t - \frac{\eta}{\sigma_i^t} g_i^t$

!!! question "怎么算出 $\sigma$？"

### 1、Root Mean Square
主要用于平衡梯度的尺度，防止梯度太大或太小，但它本身不是一个优化算法，只是一个度量或规范化手段，常见于比如 AdaGrad 这种方法。

$$
\theta_i^{1} \leftarrow \theta_i^{0} - \frac{\eta}{\sigma_i^{0}} g_i^{0} \quad\quad \sigma_i^{0} = \sqrt{(g_i^{0})^2} = |g_i^{0}|
$$

$$
\theta_i^{2} \leftarrow \theta_i^{1} - \frac{\eta}{\sigma_i^{1}} g_i^{1} \quad\quad \sigma_i^{1} = \sqrt{\frac{1}{2} \left[ (g_i^{0})^2 + (g_i^{1})^2 \right]}
$$

$$
\theta_i^{3} \leftarrow \theta_i^{2} - \frac{\eta}{\sigma_i^{2}} g_i^{2} \quad\quad \sigma_i^{2} = \sqrt{\frac{1}{3} \left[ (g_i^{0})^2 + (g_i^{1})^2 + (g_i^{2})^2 \right]}
$$

$$
\vdots
$$

$$
\theta_i^{t+1} \leftarrow \theta_i^{t} - \frac{\eta}{\sigma_i^{t}} g_i^{t} \quad\quad \sigma_i^{t} = \sqrt{ \frac{1}{t+1} \sum_{i=0}^{t} (g_i^{t})^2 }
$$

- 坡度平缓 → 算出的gradient小 → $\sigma$ 小 → $\frac{\eta}{\sigma}$ 大 → 下降的快

---

### 2、RMSProp
是为了解决 AdaGrad 中“学习率衰减太快”的问题而提出的，RMSProp 让优化器更多地关注 “当前和最近的梯度”，而不是 “所有历史的梯度”，这样可以保持一个合理的学习率，不会让学习率因为历史梯度积累而快速变得很小。

$$
\theta_i^{1} \leftarrow \theta_i^{0} - \frac{\eta}{\sigma_i^{0}} g_i^{0} \quad\quad \sigma_i^{0} = \sqrt{(g_i^{0})^2} \quad\quad 0 < \alpha < 1
$$

$$
\theta_i^{2} \leftarrow \theta_i^{1} - \frac{\eta}{\sigma_i^{1}} g_i^{1} \quad\quad \sigma_i^{1} = \sqrt{ \alpha (\sigma_i^{0})^2 + (1 - \alpha)(g_i^{1})^2 }
$$

$$
\theta_i^{3} \leftarrow \theta_i^{2} - \frac{\eta}{\sigma_i^{2}} g_i^{2} \quad\quad \sigma_i^{2} = \sqrt{ \alpha (\sigma_i^{1})^2 + (1 - \alpha)(g_i^{2})^2 }
$$

$$
\vdots
$$

$$
\theta_i^{t+1} \leftarrow \theta_i^{t} - \frac{\eta}{\sigma_i^{t}} g_i^{t} \quad\quad \sigma_i^{t} = \sqrt{ \alpha (\sigma_i^{t-1})^2 + (1 - \alpha)(g_i^{t})^2 }
$$

![RMSProp.png](../assets/images/DL/RMSProp.png)

---

### 3、Adam

$=\text{RMSProp + Momentum}$

```python
optimizer = optim.Adam(model.parameters(), lr=0.01)
```

---

### 4、Learning rate Scheduling

- 学习率衰减（Learning rate decay）
    - 随时间增加减小学习率 $\eta$
- 预热（Warm up）
    - $\eta$ 先增大后减小

??? info
    **结合关系图**
    
    $\text{最终更新公式} = \underbrace{\eta}_{\text{全局}} \times \underbrace{\text{调度因子}(\text{scheduler})}_{\text{随epoch调整}} \times \underbrace{\text{自适应比例}(\text{如} \frac{1}{\sigma_i})}_{\text{局部，RMS/Adam}}$
    
    **总结它们的关系**：
    
    |                          | 功能                     | 影响的层面             | 作用                                     |
    | ------------------------ | ------------------------ | ---------------------- | ---------------------------------------- |
    | RMSProp/Adam             | 自适应调整不同参数的步长 | **参数层面（局部）**   | 避免某些参数因梯度过大或过小而更新不稳定 |
    | Learning Rate Scheduling | 随训练进度调整整体学习率 | **优化器的全局学习率** | 保证训练初期大胆搜索，后期精细收敛       |

---

## 五、分类

