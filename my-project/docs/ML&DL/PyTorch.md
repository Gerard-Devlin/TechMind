---
icon: simple/pytorch
---


[TOC]

---

## ä¸€ã€`dataset`å’Œ`dataloader`

- **Dataset**ï¼šå­˜å‚¨æ•°æ®æ ·æœ¬å’ŒæœŸæœ›å€¼
- **Dataloader**ï¼šå°†æ•°æ®åˆ†ç»„ä¸ºæ‰¹æ¬¡ï¼Œæ”¯æŒå¤šè¿›ç¨‹

```python
dataset = MyDataset(file)
dataloader = DataLoader(dataset, batch_size, shuffle=True)
```

```python
from torch.utils.data import Dataset, DataLoader

class MyDataset(Dataset):
    def __init__(self, file):
        self.data = ...  # è¯»å–æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†

    def __getitem__(self, index):
        return self.data[index]  # æ¯æ¬¡è¿”å›ä¸€ä¸ªæ ·æœ¬

    def __len__(self):
        return len(self.data)  # è¿”å›æ•°æ®é›†çš„å¤§å°
```

---

## äºŒã€`tensor`

- æ¦‚å¿µï¼šé«˜ç»´çŸ©é˜µ
    - 1-Dï¼šå£°éŸ³
      - 2-Dï¼šé»‘ç™½å›¾ç‰‡
      - 3-Dï¼šå½©è‰²ç…§ç‰‡
      - â€¦â€¦

---

### 1ã€å¸¸è§æ“ä½œ

- æŸ¥çœ‹å¤§å°ã€ç»´åº¦

    ```python
    .shape()	# æŸ¥çœ‹çŸ©é˜µå¤§å°
    ```

- ç›´æ¥ä»æ•°æ®ï¼ˆåˆ—è¡¨æˆ–numpy.ndarrayï¼‰åˆ›å»ºå¼ é‡
    ```python
    x = torch.tensor([[1, -1], [-1, 1]])
    x = torch.from_numpy(np.array([[1, -1], [-1, 1]]))
    ```

- åˆ›å»ºå…¨é›¶æˆ–å…¨ä¸€çš„å¼ é‡
    ```python
    x = torch.zeros([2, 2])  # å½¢çŠ¶ä¸º2x2çš„å…¨é›¶å¼ é‡
    x = torch.ones([1, 2, 5])  # å½¢çŠ¶ä¸º1x2x5çš„å…¨ä¸€å¼ é‡
    ```

- è½¬ç½®

    ```python
    x = x.transpose(0, 1)
    ```

- `sqeeze`/`unsqeeze`

    ```python
    x = x.sqeeze(0)	# å‹ç¼©ç¬¬ä¸€ä¸ªç»´åº¦
    x = x.unsqeeze(1)	# ç¬¬äºŒä¸ªç»´åº¦æ¢å¤æˆ 1
    ```

- `cat`

    ```python
    w = torch.cat([x, y, z], dim=1)	# åœ¨ç¬¬äºŒä¸ªç»´åº¦ä¸Šè¿›è¡Œåˆå¹¶
    ```

---

### 2ã€è®¾å¤‡

- é»˜è®¤æƒ…å†µä¸‹ï¼Œå¼ é‡å’Œæ¨¡å—å°†åœ¨**CPU**ä¸Šè¿›è¡Œè®¡ç®—ï¼Œä½¿ç”¨ `.to()` æ–¹æ³•å°†å¼ é‡ç§»åŠ¨åˆ°é€‚å½“çš„è®¾å¤‡

- **CPU**
  
  ```python
  x = x.to('cpu')
  ```
  
- **GPU**
  
  ```python
  x = x.to('cuda')
  ```
  
!!! tip
    - **æ£€æŸ¥è®¡ç®—æœºæ˜¯å¦æœ‰ NVIDIA GPU**
        - ä½¿ç”¨ `torch.cuda.is_available()` å‡½æ•°æ¥æ£€æŸ¥ä½ çš„è®¡ç®—æœºæ˜¯å¦æ”¯æŒ NVIDIA GPUã€‚
  
    è¿™ä¸ªå‡½æ•°ä¼šè¿”å›ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œå¦‚æœè®¡ç®—æœºæœ‰å¯ç”¨çš„ NVIDIA GPU å¹¶ä¸”æ­£ç¡®å®‰è£…äº† CUDAï¼Œé‚£ä¹ˆè¿”å› `True`ï¼Œå¦åˆ™è¿”å› `False`ã€‚

---

### 3ã€è‡ªåŠ¨æ±‚å¯¼

```python
x = torch.tensor([[1., 0.], [-1., 1.]], requires_grad=True)	# åˆ›å»ºå¼ é‡å¹¶è®¾ç½® requires_grad=True
z = x.pow(2).sum()
z.backward()	# æ‰§è¡Œåå‘ä¼ æ’­
x.grad		# æŸ¥çœ‹æ¢¯åº¦
```

---

## ä¸‰ã€`torch.nn`

### 1ã€æ¿€æ´»å‡½æ•°

```python
nn.sigmoid()
nn.ReLU()
nn.Linear(in_feature, out_feature)	# å…¨è¿æ¥
```

```python
import torch.nn as nn

class MyModel(nn.Module):
    def __init__(self):
        super(MyModel, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(10, 32),  # è¾“å…¥å±‚åˆ°éšè—å±‚çš„çº¿æ€§å˜æ¢
            nn.Sigmoid(),       # æ¿€æ´»å‡½æ•°
            nn.Linear(32, 1)    # éšè—å±‚åˆ°è¾“å‡ºå±‚çš„çº¿æ€§å˜æ¢
        )
    
    def forward(self, x):
        return self.net(x)    # è®¡ç®—ç¥ç»ç½‘ç»œçš„è¾“å‡º
```

---

### 2ã€æŸå¤±å‡½æ•°

- **å‡æ–¹è¯¯å·®ï¼ˆMean Squared Errorï¼‰**ï¼šç”¨äºå›å½’ä»»åŠ¡ã€‚

   ```python
   criterion = nn.MSELoss()
   ```

- **äº¤å‰ç†µï¼ˆCross Entropyï¼‰**ï¼šç”¨äºåˆ†ç±»ä»»åŠ¡ã€‚

   ```python
   criterion = nn.CrossEntropyLoss()
   ```

- **è®¡ç®—æŸå¤±**ï¼š

   ```python
   loss = criterion(model_output, expected_value)
   ```

---

## å››ã€`torch.optim`

```python
optimizer = torch.optim.SGD(model.parameters(), lr, momentum=0)
```

---

## äº”ã€è®­ç»ƒæµç¨‹

- è®¾ç½®

```python
dataset = MyDataset(file)  # è¯»å–æ•°æ® via MyDataset
tr_set = DataLoader(dataset, 16, shuffle=True)  # å°†æ•°æ®é›†æ”¾å…¥ DataLoader
model = MyModel().to(device)  # æ„å»ºæ¨¡å‹å¹¶ç§»åŠ¨åˆ°è®¾å¤‡ (cpu/cuda)
criterion = nn.MSELoss()  # è®¾ç½®æŸå¤±å‡½æ•°
optimizer = torch.optim.SGD(model.parameters(), 0.1)  # è®¾ç½®ä¼˜åŒ–å™¨
```

- è®­ç»ƒå¾ªç¯

```python
for epoch in range(n_epochs):  # è¿­ä»£ n_epochs
    model.train()  # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
    for x, y in tr_set:  # è¿­ä»£æ•°æ®åŠ è½½å™¨
        optimizer.zero_grad()  # é‡ç½®æ¢¯åº¦
        x, y = x.to(device), y.to(device)  # å°†æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡ (cpu/cuda)
        pred = model(x)  # å‰å‘ä¼ æ’­ (è®¡ç®—è¾“å‡º)
        loss = criterion(pred, y)  # è®¡ç®—æŸå¤±
        loss.backward()  # è®¡ç®—æ¢¯åº¦ (åå‘ä¼ æ’­)
        optimizer.step()  # ä½¿ç”¨ä¼˜åŒ–å™¨æ›´æ–°æ¨¡å‹å‚æ•°
```

- äº¤å‰éªŒè¯å¾ªç¯

```python
model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
total_loss = 0  # åˆå§‹åŒ–æ€»æŸå¤±
for x, y in dv_set:  # è¿­ä»£æ•°æ®åŠ è½½å™¨
    x, y = x.to(device), y.to(device)  # å°†æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡ (cpu/cuda)
    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—
        pred = model(x)  # å‰å‘ä¼ æ’­ (è®¡ç®—è¾“å‡º)
        loss = criterion(pred, y)  # è®¡ç®—æŸå¤±
        total_loss += loss.cpu().item() * len(x)  # ç´¯ç§¯æŸå¤±
avg_loss = total_loss / len(dv_set.dataset)  # è®¡ç®—å¹³å‡æŸå¤±
```

- æµ‹è¯•é›†å¾ªç¯

```python
model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
preds = []  # åˆå§‹åŒ–é¢„æµ‹åˆ—è¡¨
for x in tt_set:  # è¿­ä»£æ•°æ®åŠ è½½å™¨
    x = x.to(device)  # å°†æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡ (cpu/cuda)
    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—
        pred = model(x)  # å‰å‘ä¼ æ’­ (è®¡ç®—è¾“å‡º)
        preds.append(pred.cpu())  # æ”¶é›†é¢„æµ‹
```

- ä¿å­˜

```python
torch.save(model.state_dict(), path)
```

- åŠ è½½

```python
ckpt = torch.load(path)
model.load_state_dict(ckpt)
```

---

!!! tip
    - **model.eval()**

        - æ”¹å˜æŸäº›æ¨¡å‹å±‚çš„è¡Œä¸ºï¼Œä¾‹å¦‚ dropout å’Œ batch normalizationã€‚
    - **with torch.no_grad()**

        - é˜²æ­¢è®¡ç®—è¢«æ·»åŠ åˆ°æ¢¯åº¦è®¡ç®—å›¾ä¸­ã€‚é€šå¸¸ç”¨äºé˜²æ­¢åœ¨éªŒè¯/æµ‹è¯•æ•°æ®ä¸Šæ„å¤–è¿›è¡Œè®­ç»ƒã€‚

---

??? example "MNIST"
    ```python title="Train + Test"
    # å¯¼å…¥æ‰€éœ€çš„åŒ…
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader
    from torchvision import datasets, transforms
    import matplotlib.pyplot as plt
    import seaborn as sns
    from sklearn.metrics import confusion_matrix
    import numpy as np
    
    # è®¾ç½®è¶…å‚æ•°
    config = {
        "device": torch.device("cuda" if torch.cuda.is_available() else "cpu"),
        "batch_size": 64,
        "learning_rate": 0.01,
        "epochs": 15,
    }
    
    # åŠ è½½æ•°æ®é›†
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
    
    train_dataset = datasets.MNIST(root="./data", train=True, transform=transform, download=True)
    test_dataset = datasets.MNIST(root="./data", train=False, transform=transform, download=True)
    train_loader = DataLoader(train_dataset, batch_size=config["batch_size"], shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=config["batch_size"], shuffle=True)
    
    # å¯è§†åŒ–æ ·æœ¬æ•°æ®
    examples = iter(train_loader)
    images, labels = next(examples)
    
    plt.figure(figsize=(10, 10))
    for i in range(16):
        plt.subplot(4, 4, i+1)
        plt.imshow(images[i][0], cmap='gray')
        plt.title(f"label:{labels[i]}")
        plt.axis('off')
    plt.show()
    
    # æ„å»ºæ¨¡å‹
    class SimpleNN(nn.Module):
        def __init__(self):
            super(SimpleNN, self).__init__()
            self.model = nn.Sequential(
                nn.Flatten(),                                 # å±•å¹³ 28x28 å›¾åƒ
                nn.Linear(28*28, 512),                        # è¾“å…¥å±‚
                nn.BatchNorm1d(512),                          # æ‰¹å½’ä¸€åŒ–
                nn.LeakyReLU(0.1),                            # LeakyReLU é˜²æ­¢æ­»ç¥ç»å…ƒ
                nn.Dropout(0.3),                              # Dropout é˜²æ­¢è¿‡æ‹Ÿåˆ
    
                nn.Linear(512, 256),                          # ä¸­é—´å±‚1
                nn.BatchNorm1d(256),
                nn.LeakyReLU(0.1),
                nn.Dropout(0.3),
    
                nn.Linear(256, 128),                          # ä¸­é—´å±‚2
                nn.BatchNorm1d(128),
                nn.LeakyReLU(0.1),
                nn.Dropout(0.3),
    
                nn.Linear(128, 10),                           # è¾“å‡ºå±‚
            )
    
        def forward(self, x):
            return self.model(x)
    
    model = SimpleNN().to(config["device"])
    
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=config["learning_rate"])
    
    # è®­ç»ƒæ¨¡å‹
    from tqdm import tqdm
    
    for epoch in range(config["epochs"]):
        total_loss = 0.0
        model.train()
    
        print(f"\nğŸ”„ Epoch {epoch+1}/{config['epochs']}")
        train_bar = tqdm(train_loader, desc="Training", dynamic_ncols=True, leave=False)
    
        for images, labels in train_bar:
            images, labels = images.to(config["device"]), labels.to(config["device"])
    
            outputs = model(images)
            loss = criterion(outputs, labels)
    
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
    
            total_loss += loss.item()
            train_bar.set_postfix(loss=loss.item())
    
        avg_loss = total_loss / len(train_loader)
        print(f"âœ… Epoch {epoch+1} finished. Average Loss: {avg_loss:.4f}")
    
    # æ¨¡å‹æµ‹è¯•
    with torch.no_grad():
        total = 0
        correct = 0
        model.eval()
        for images, labels in tqdm(test_loader, desc="Testing", dynamic_ncols=True, leave=False):
            images, labels = images.to(config["device"]), labels.to(config["device"])
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
        print(f"Test Accuracy: {100 * correct / total:.2f}%")
    
    # ä¿å­˜æ¨¡å‹
    torch.save(model.state_dict(), "model.pth")
    
    # åŠ è½½æ¨¡å‹å¹¶é¢„æµ‹
    model.load_state_dict(torch.load("model.pth"))
    model.eval()
    
    images, labels = next(iter(test_loader))
    images, labels = images.to(config["device"]), labels.to(config["device"])
    outputs = model(images)
    _, predicted = torch.max(outputs.data, 1)
    print(f"Test Accuracy: {100 * correct / total:.2f}%")
    
    # å¯è§†åŒ–æ··æ·†çŸ©é˜µ
    model.eval()
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(config["device"]), labels.to(config["device"])
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    # è®¡ç®—æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_preds)
    
    # æ˜¾ç¤ºçƒ­åŠ›å›¾
    plt.figure(figsize=(20, 20))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=range(10), yticklabels=range(10))
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.title("Confusion Matrix")
    plt.show()
    ```
    
    ```python title="GUI"
    import tkinter as tk
    from tkinter import Canvas, Button, Label
    import torch
    import torch.nn as nn
    from PIL import Image, ImageDraw, ImageOps
    from torchvision import transforms
    
    
    # ======== 1. æ¨¡å‹ç»“æ„ ========= #
    class SimpleNN(nn.Module):
        def __init__(self):
            super(SimpleNN, self).__init__()
            self.model = nn.Sequential(
                nn.Flatten(),                                 # å±•å¹³ 28x28 å›¾åƒ
                nn.Linear(28*28, 512),                        # è¾“å…¥å±‚
                nn.BatchNorm1d(512),                          # æ‰¹å½’ä¸€åŒ–
                nn.LeakyReLU(0.1),                            # LeakyReLU é˜²æ­¢æ­»ç¥ç»å…ƒ
                nn.Dropout(0.3),                              # Dropout é˜²æ­¢è¿‡æ‹Ÿåˆ
    
                nn.Linear(512, 256),                          # ä¸­é—´å±‚1
                nn.BatchNorm1d(256),
                nn.LeakyReLU(0.1),
                nn.Dropout(0.3),
    
                nn.Linear(256, 128),                          # ä¸­é—´å±‚2
                nn.BatchNorm1d(128),
                nn.LeakyReLU(0.1),
                nn.Dropout(0.3),
    
                nn.Linear(128, 10),                           # è¾“å‡ºå±‚
            )
    
        def forward(self, x):
            return self.model(x)
    
    # ======== 2. å›¾åƒé¢„å¤„ç†å‡½æ•° ========= #
    def preprocess_image(img):
        img = img.convert("L")  # è½¬æ¢ä¸ºç°åº¦å›¾ éå¸¸é‡è¦
        img = ImageOps.pad(img, (28, 28), color=0)  # å¡«å……å›¾åƒ
    
        # å½’ä¸€åŒ–å‚æ•°ï¼šæ ¹æ® MNIST æ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))  # ä½¿ç”¨ MNIST æ•°æ®é›†çš„æ ‡å‡†åŒ–å‚æ•°
        ])
        return transform(img).unsqueeze(0)
    
    # ======== 3. GUI åº”ç”¨ç±» ========= #
    class App:
        def __init__(self):
            self.window = tk.Tk()
            self.window.title("MNIST")
    
            self.canvas = Canvas(self.window, width=280, height=280, bg='black')
            self.canvas.grid(row=0, column=0, columnspan=4)
            self.canvas.bind('<B1-Motion>', self.draw)
    
            self.label = Label(self.window, text="Prediction: None", font=("Arial", 18))
            self.label.grid(row=1, column=0, columnspan=4)
            self.prob_label = Label(self.window, text="Probabilities:", font=("Arial", 12), justify="left", anchor="w")
            self.prob_label.grid(row=3, column=0, columnspan=4, sticky="w")  # å·¦å¯¹é½
    
            Button(self.window, text="Predict", command=self.predict).grid(row=2, column=0)
            Button(self.window, text="Clear", command=self.clear).grid(row=2, column=1)
            Button(self.window, text="Exit", command=self.window.quit).grid(row=2, column=2)
    
            self.image = Image.new("L", (280, 280), color=0)
            self.draw_interface = ImageDraw.Draw(self.image)
    
            # ç¡®ä¿é€‰æ‹©è®¾å¤‡
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
            # åŠ è½½æ¨¡å‹
            self.model = SimpleNN().to(self.device)
            self.model.load_state_dict(torch.load("best_model.pth", map_location=self.device))
            self.model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
    
            self.window.mainloop()
    
        def draw(self, event):
            x, y = event.x, event.y
            r = 8
            self.canvas.create_oval(x - r, y - r, x + r, y + r, fill='white', outline='white')
            self.draw_interface.ellipse([x - r, y - r, x + r, y + r], fill=255)
    
        def clear(self):
            self.canvas.delete("all")
            self.image = Image.new("L", (280, 280), color=0)
            self.draw_interface = ImageDraw.Draw(self.image)
            self.label.config(text="Prediction: None")
    
        def predict(self):
            img_tensor = preprocess_image(self.image).to(self.device)  # å°†å›¾åƒæ•°æ®ä¼ åˆ°è®¾å¤‡
            output = self.model(img_tensor)
            prob = torch.softmax(output, dim=1)
            pred = torch.argmax(prob, dim=1).item()
            conf = prob[0][pred].item()
            self.label.config(text=f"Prediction: {pred} ({conf:.2%})")
    
            # æ„å»ºæ¦‚ç‡æ–‡æœ¬
            prob_text = "Probabilities:\n"
            for i, p in enumerate(prob[0]):
                prob_text += f"  {i}: {p.item():.2%}\n"
    
            # è®¾ç½®åˆ°ç•Œé¢ä¸Š
            self.prob_label.config(text=prob_text)
    
    
    if __name__ == '__main__':
        App()
    ```

---
